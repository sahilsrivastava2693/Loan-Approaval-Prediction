{"cells":[{"cell_type":"markdown","source":["__Sometimes it can be quite unpredictable to determine whether a customer would be able to repay their loan. The primary factors to determine whether the customer will be able to payback is a challenging and unpredictable process. It can also be time consuming and tedious considering the number of factors involved during the loan application stage from the customer's end. By analyzing the data with over 25 features, we aim to determine factors that will play a key role in creating a predictive model to assist banks in forecasting whether a customer would be able to repay a loan amount or not. The input parameters from customers will be used against the model to determine the probability of payback or the chances of a loan getting charged-off. This can certainly assist the banks in predicting and accordingly making a decision before issuing a particular loan. The predictive model can replace the initial steps of the prequalification process across all financial institutions thus saving time and efforts of both customers and loan representatives.__\n\n__Dataset:__ Data is collected from Lending Club Loan Data website which contains information for all loans issued through 2007-2015 to forecast which customer will repay the loan amount in given time span.\n\n__Goal of the Project:__ To forecast the probability of a customer being able to pay off their loan."],"metadata":{}},{"cell_type":"code","source":["# Imports and setup\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns"],"metadata":{"collapsed":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":["loans = pd.read_csv('/dbfs/FileStore/tables/loan.csv', low_memory = False)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["## Exploring the Dataset"],"metadata":{}},{"cell_type":"code","source":["loans.head()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# Let's take a look at the different columns and what data they contain\n#cols = loans.columns[0:10]  # cycle through 0:10, 10:20, ...\ncols = ['loan_amnt', 'term', 'int_rate', 'installment', 'emp_length']  # or pick specific columns\nprint(cols)\nfor col in cols:\n    print(loans[col].describe())  # describe one by one in case of mixed types"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["\n# Parse term durations: ' 36 months' -> 36 (numeric)\nprint(\"term before:-\")\nprint(loans.term.head())\nloans.term = pd.to_numeric(loans.term.str[:3])\nprint(\"term after:-\")\nprint(loans.term.head())"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["# Parse emp_length: '< 1 year' -> 1.0, '1 year' -> 1.0, '7 year' -> 7.0, etc. (numeric)\nprint(\"emp_length before:-\")\nprint(loans.emp_length.head())\nloans.emp_length = loans.emp_length.str.extract(\"(\\d+)\", expand=False).map(float)\nprint(\"emp_length after:-\")\nprint(loans.emp_length.head())"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# For the categorical variables we have replaced NaN with 'Unknown'.\n# We will fill verification_status_joint using the value in verification_status as these are all individual applications and these values are not filled out.\nloans['verification_status_joint'].fillna(loans['verification_status'], inplace=True)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["strColumns = loans.select_dtypes(include=['object']).columns.values\nloans[strColumns] = loans[strColumns].fillna('Unknown')"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["#Check that all the NaN values have been replaced\nloans.select_dtypes(exclude=[np.number]).isnull().sum()"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["# First we will check the number of missing values for each of the columns\nloans.select_dtypes(include=[np.number]).isnull().sum()"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["# The first columns that we are going to update are annual_inc_joint, dti_joint and verification_status_joint. For individual accounts these are blank but we want to use the joint values so we will populate these with the individual values for individual accounts.\nloans[loans['application_type'] != 'INDIVIDUAL']['annual_inc_joint'].isnull().sum()"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["loans['annual_inc_joint'].fillna(loans['annual_inc'], inplace=True)\nloans['dti_joint'].fillna(loans['dti'], inplace=True)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["#For the remainder of the missing values we are going to fix the missing values by replacing any NaN values with the mean values\nstrColumns = loans.select_dtypes(include=[np.number]).columns.values\nloans[strColumns] = loans[strColumns].fillna(loans[strColumns].mean())"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["# What is the distribution of loans by status?\nloans_by_status = loans.groupby('loan_status')\nprint(loans_by_status['loan_status'].count())\nloans_by_status['loan_status'].count().plot(kind='bar')"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["# What is the distribution of loans by purpose?\nloans_by_purpose = loans.groupby('purpose')\nprint(loans_by_purpose['purpose'].count())\nloans_by_purpose['purpose'].count().plot(kind='bar')\ndisplay()"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["# What is the distribution of loans by term?\nloans_by_term = loans.groupby('term')\nprint(loans_by_term['term'].count())\nloans_by_term['term'].count().plot(kind='bar')\ndisplay()"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["# Let's setup a binary classification target 'default': 0 => Fully Paid, 1 => Charged Off\nloans_subset = loans.copy()\nloans_subset['default'] = None\nloans_subset.loc[(loans_subset.loan_status == 'Fully Paid') | (loans_subset.loan_status == 'Does not meet the credit policy. Status:Fully Paid'), 'default'] = 0\nloans_subset.loc[(loans_subset.loan_status == 'Charged Off') | (loans_subset.loan_status == 'Does not meet the credit policy. Status:Charged Off'), 'default'] = 1\n\n# Drop loans that haven't been terminated yet (we don't know what their final status will be)\nloans_subset = loans_subset[~loans_subset.default.isnull()]\nprint(\"Data subset size: {}\".format(loans_subset.shape))\n\n# Re-encode 'default' column as numeric (0 or 1)\nloans_subset['default'] = pd.to_numeric(loans_subset['default'])"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["## Detailed Information of the features"],"metadata":{}},{"cell_type":"markdown","source":["## Input Variables:\n\n\n## Application Stage Data:\n\n__member_id:__ The month which the loan was funded\n\n__issue_d:__ A unique LC assigned Id for the borrower member.\n\n\n\n## Loan Application Details:\n\n__addr_state:__\tThe state provided by the borrower in the loan application\n\n__emp_length:__\tEmployment length in years. Possible values are between 0 and 10 where 0 means less than one year and 10 means ten or more years. \n\n__emp_title:__\tThe job title supplied by the Borrower when applying for the loan.\n\n__home_ownership:__\tThe home ownership status provided by the borrower during registration. Our values are: RENT, OWN, MORTGAGE, OTHER.\n\n__installment:__\tThe monthly payment owed by the borrower if the loan originates.\n\n__int_rate:__\tInterest Rate on the loan\n\n__loan_amnt:__\tThe listed amount of the loan applied for by the borrower. If at some point in time, the credit department reduces the loan amount, then it will be reflected in this value.\n\n__purpose:__\tA category provided by the borrower for the loan request. \n\n__term:__\tThe number of payments on the loan. Values are in months and can be either 36 or 60.\n\n__title:__\tThe loan title provided by the borrower\n\n__verified_status_joint:__\tIndicates if the co-borrowers' joint income was verified by LC, not verified, or if the income source was verified\n\n__zip_code:__\tThe first 3 numbers of the zip code provided by the borrower in the loan application.\n\n\n\n## Borrowers Creditworthiness:\n\n__annual_inc:__\tThe self-reported annual income provided by the borrower during registration.\n\n__delinq_2yrs:__\tThe number of 30+ days past-due incidences of delinquency in the borrower's credit file for the past 2 years\n\n__dti:__\tA ratio calculated using the borrower’s total monthly debt payments on the total debt obligations, excluding mortgage and the requested LC loan, divided by the borrower’s self-reported monthly income.\n\n__earliest_cr_line:__\tThe month the borrower's earliest reported credit line was opened\n\n__inq_last_6mths:__\tThe number of inquiries in past 6 months (excluding auto and mortgage inquiries)\n\n__mths_since_last_delinq:__\tThe number of months since the borrower's last delinquency.\n\n__open_acc:__\tThe number of open credit lines in the borrower's credit file.\n\n__revol_bal:__\tTotal credit revolving balance\n\n__revol_util:__\tRevolving line utilization rate, or the amount of credit the borrower is using relative to all available revolving credit.\n\n__total_acc:__\tThe total number of credit lines currently in the borrower's credit file\n\n\n\n## Public Records:\n\n__mths_since_last_record:__\tThe number of months since the last public record.\n\n__pub_rec:__\tNumber of derogatory public records\n\n\n\n## Output Variable (Desired Target)\n\n__default:__ has the customer able to pay off their loan? (binary: 'yes','no')"],"metadata":{}},{"cell_type":"code","source":["# We only want to keep information that is available at loan *application* stage\napplication_cols = [\n    # Identifiers and dates\n    #'id',  # used as index column\n    'member_id',\n    'issue_d',\n    \n    # Loan application details\n    #'application_type',  # all 'INDIVIDUAL'\n    'loan_amnt',  # $ applied for\n    'term',  # 36 or 60 months\n    'int_rate',  # % annual (?) interest rate\n    'installment',  # $ monthly payment\n    'emp_title',  # employee/employer title\n    'emp_length',  # 0-10+ years\n    'home_ownership',  # RENT, OWN, MORTGAGE, etc.\n    'verification_status',  # mostly 'Not Verified'\n    #'verification_status_joint',  # all 0\n    'purpose',  # 'debt_consolidation', 'small_business', etc.\n    'title',  # text\n    #'desc',  # text, too verbose, may contain updates after application stage\n    'zip_code',  # 100XX\n    'addr_state',  # covered by zip_code?\n    \n    # Additional loan listing details\n    #'initial_list_status',  # all 'f'\n    #'policy_code',  # all 1\n    #'url',  # unqiue per loan\n\n    # Borrower's creditworthiness\n    'annual_inc', #'annual_inc_joint',  # income ($; individual only, no joint loans)\n    'dti', #'dti_joint',  # debt-to-income ratio (%; individual only, no joint loans)\n    'revol_bal', 'revol_util',  # revolving accounts: balance ($), utilization (%)\n    #'tot_cur_bal', 'max_bal_bc',  # overall balance: total current, max; all null\n    'earliest_cr_line', 'total_acc', 'open_acc',  # credit accounts\n    'inq_last_6mths', #'inq_last_12m', 'inq_fi',  # credit inquiries (only 6 mths available)\n    'delinq_2yrs', 'mths_since_last_delinq', #'acc_now_delinq',  # delinquency (acc_now_delinq is mostly 0)\n    #'tot_coll_amt', 'collections_12_mths_ex_med',  # collections; all null or 0\n    #'open_il_6m', 'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il', 'total_bal_il', 'il_util',  # installment accounts; all null\n    #'open_acc_6m', 'open_rv_12m', 'open_rv_24m', 'total_rev_hi_lim', 'total_cu_tl', 'all_util', # revolving trading accounts; all null\n    \n    # Public records\n    'pub_rec', 'mths_since_last_record',\n    #'mths_since_last_major_derog',  # all null\n\n    # Loan rating as determined by lender (potential multi-class targets to predict?)\n    #'grade',\n    #'sub_grade',\n\n    # Desired binary target to predict\n    'default'\n]\n\nloans_small = loans_subset[application_cols]\n\n# Check selected data subset\nprint(\"Small dataset has {} rows, {} columns:\".format(len(loans_small), len(loans_small.columns)))\nprint(loans_small.head())\nprint(\"Class distribution:\")\nprint(loans_small.groupby('default')['default'].count())"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["# Displaying Heatmap of Correlation Matrix\n\ncorr=loans_small.corr()\ncorr = (corr)\nplt.figure(figsize=(40,40))\nsns.heatmap(corr, cbar = True,  square = True, annot=True, fmt= '.2f',annot_kws=\n\n{'size': 15},\n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values)\nsns.plt.title('Heatmap of Correlation Matrix')\ndisplay()"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["loans_small1 = loans_small"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["loans_small.head(5)"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":["### Feature Extraction"],"metadata":{}},{"cell_type":"code","source":["# removing irrelevant columns after analyzing heatmap\n\nloansdf = loans_small1.drop([\n'member_id',\n'issue_d',\n'emp_title',\n'title',\n'zip_code',\n'addr_state',\n'earliest_cr_line',\n'total_acc',\n'open_acc',\n'inq_last_6mths',\n'delinq_2yrs',\n'mths_since_last_delinq',\n'pub_rec',\n'mths_since_last_record',\n'default' \n],axis=1)"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["# Displaying final heatmap of correlation matrix\n\ncorr=loansdf.corr()\ncorr = (corr)\nplt.figure(figsize=(15,15))\nsns.heatmap(corr, cbar = True,  square = True, annot=True, fmt= '.2f',annot_kws=\n\n{'size': 20},\n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values)\nsns.plt.title('Heatmap of Correlation Matrix')\ndisplay()"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":["### Extracting the desired features and target column into a Data Frame"],"metadata":{}},{"cell_type":"code","source":["# Specify a subset of feature columns and a target to predict ('default')\nfeature_cols = [\n    'loan_amnt', 'term', 'int_rate', 'installment', 'purpose',\n    #'emp_title', # free text\n    'emp_length', 'home_ownership',\n    #'zip_code', 'addr_state',  # categorical, but too many levels\n    'annual_inc', 'dti',\n    'revol_bal', 'revol_util',\n    'verification_status'\n]\n\ntarget_col = 'default'\n\n# Create the final dataset we'll use for classification\nkeep_cols = feature_cols + [target_col]\nloans_final = loans_small[keep_cols]\n\n# Drop samples with null values (few enough that we can ignore)\nloans_final.dropna(inplace=True)\n\nprint(\"Final dataset: {} features, {} samples\".format(len(loans_final.columns), len(loans_final)))\nprint(loans_final.head())\nprint(\"Final class distribution (after dropping nulls):\")\nclass_counts = loans_final.groupby(target_col)[target_col].agg({\n    'count': len,\n    'ratio': lambda x: float(len(x)) / len(loans_final)\n})\nprint(class_counts)\n\n# Extract desired features and target column\nX = loans_final[feature_cols]\ny = loans_final[target_col]\nprint(\"{} features: {}\".format(len(X.columns), X.columns))\nprint(\"Target: {}\".format(y.name))"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["# label encoding the categorical values for easier processing\nfrom sklearn.preprocessing import LabelEncoder\ntestDF = loans_final.apply(LabelEncoder().fit_transform)"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["print(testDF)"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["# normalizing the values for better results\nfrom sklearn import preprocessing\n\nnormalized_npArray = preprocessing.normalize(testDF)\nnormalized_df = pd.DataFrame(normalized_npArray, columns = testDF.columns)\nnormalized_df.default = testDF.default"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":["### We can find the correlation of feature among themselves by performing the correlation on the dataframe"],"metadata":{}},{"cell_type":"code","source":["# finding correlation of target with other variables\ncorr = abs(normalized_df.corr())\ncorr.sort_values([\"default\"], ascending = False, inplace = True)\n\ncorr_df = pd.DataFrame(corr.default)\ncorr_df['Features'] = corr_df.index\ncorr_df = corr_df[['Features', 'default']]\ncorr_df = corr_df[corr_df.default != 1]\nsns.barplot(x = 'Features', y = 'default', data = corr_df)\nplt.xticks(rotation=60)\nplt.show()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["# Encode categorical variables among features\ncategorical_vars = ['home_ownership', 'purpose', 'verification_status']\nX = pd.get_dummies(X, columns=categorical_vars, drop_first=True)\nprint(\"{} features after encoding categorical variables: {}\".format(len(X.columns), X.columns))"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["original_df = testDF.copy()\n# Always scale your data with a mean of 0 and a standard deviation of 1.. the models can work better in that regards\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(testDF)\n# test = StandardScaler().fit(X).transform(X)\nX = scaler.transform(testDF)\nX = pd.DataFrame(X , columns=original_df.columns)\nX.head()"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["# Split into training and test sets\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\nprint(\"Training set: {} samples, test set: {} samples\".format(len(X_train), len(X_test)))\nprint(\"Training set: {} samples, test set: {} samples\".format(len(y_train), len(y_test)))"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["# Common sklearn imports\nfrom sklearn.metrics import classification_report\n\n# Define a simple train-predict utility function\ndef train_predict(clf, X_train, X_test, y_train, y_test):\n    \"\"\"Train clf on <X_train, y_train>, predict <X_test, y_test>; return y_pred.\"\"\"\n    print(\"Training a {}...\".format(clf.__class__.__name__))\n    %time clf.fit(X_train, y_train)\n    print(clf)\n    \n    print(\"Predicting test labels...\")\n    y_pred = clf.predict(X_test)\n    return y_pred"],"metadata":{"collapsed":true},"outputs":[],"execution_count":39},{"cell_type":"code","source":["loans_final.head(10)"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"markdown","source":["__In order to perform the analysis on data, we divided it into training, validation and testing data. The ratio we took is 60:30:10 respectively.__"],"metadata":{}},{"cell_type":"code","source":["#In order to avoid biasness, we will divide the dataset by splitting into yes and no and then taking equal proportions from both\n# This is done to ensure that that the percentage of yes and no in tarining, validationa and testing remain constant\n\nyes_DF = loans_final[loans_final['default']==1]\nno_DF = loans_final[loans_final['default']==0]\n\n#creating spark df from pandas df\ntest_sdf = sqlContext.createDataFrame(loans_final)\nyes_sdf = sqlContext.createDataFrame(yes_DF)\nno_sdf = sqlContext.createDataFrame(no_DF)\n\n#dividing data into training, validation and testing\ntraining_yes, validation_yes, testing_yes = yes_sdf.randomSplit([0.6, 0.3, 0.1], seed=0)\ntraining_no, validation_no, testing_no = no_sdf.randomSplit([0.6, 0.3, 0.1], seed=0)\n\n#Combining the yes/no dataframes into single dataframes\ntraining = training_yes.unionAll(training_no)\nvalidation = validation_yes.unionAll(validation_no)\ntesting = testing_yes.unionAll(testing_no)\n\n#show the count\nprint(training.count())\nprint(validation.count())\nprint(testing.count())"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":["from pyspark.sql import functions as fn\nfrom pyspark.ml import Pipeline, PipelineModel, feature, regression, classification, evaluation\n\nva = feature.VectorAssembler(inputCols=['loan_amnt', 'term', 'int_rate', 'installment', \n    #'emp_title', # free text\n    'emp_length', \n    #'zip_code', 'addr_state',  # categorical, but too many levels\n    'annual_inc', 'dti',\n    'revol_bal', 'revol_util'], outputCol='features')"],"metadata":{"collapsed":true},"outputs":[],"execution_count":43},{"cell_type":"markdown","source":["__ We plan to use various classification methods to find the best model among the different models we would try to implement.__"],"metadata":{}},{"cell_type":"code","source":["#Logistic Regression\nfrom pyspark.ml.classification import LogisticRegression\nlr = classification.LogisticRegression(labelCol=\"default\" , featuresCol=\"features\")\nlr_pipeline = Pipeline(stages=[va, lr])\nlr_pipeline_model = lr_pipeline.fit(training)"],"metadata":{"collapsed":true},"outputs":[],"execution_count":45},{"cell_type":"code","source":["#Evaluating the accuracy of logistic model\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nbce = BinaryClassificationEvaluator()\nbce.setLabelCol('default')\nbce.evaluate(lr_pipeline_model.transform(validation))"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"markdown","source":["__The accuracy of Logistic Regression is around 69.41%.__"],"metadata":{}},{"cell_type":"code","source":["#Trying to increase the complexity of the models by polynomial expansion\n\npolynomial_levels = [2,3,4]\n\nfor level in polynomial_levels:\n    pe = feature.PolynomialExpansion(degree=level, inputCol='features', outputCol='all_features')\n    lr_2 = classification.LogisticRegression(labelCol=\"default\" , featuresCol=\"all_features\")\n    pipeline_2 = Pipeline(stages=[va, pe,lr_2])\n    lr_pipeline_model_2 = pipeline_2.fit(training)\n    print('Accuracy with', level , 'degrees:', bce.evaluate(lr_pipeline_model_2.transform(validation)))"],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"markdown","source":["__After adding more polynomial levels(2,3,4), it does not show a significance increase in the accuracy level.__"],"metadata":{}},{"cell_type":"code","source":["#Adding elastic net regularization to see if the accuracy can be increased over the models.\n\npolynomial_levels = [1,2,3,4]\n\nreg_param = 0.02\nen_param = 0.3\n\nfor level in polynomial_levels:\n    pe = feature.PolynomialExpansion(degree=level, inputCol='features', outputCol='all_features')\n    lr_2 = classification.LogisticRegression(labelCol=\"default\" , featuresCol=\"all_features\").setRegParam(reg_param).\\\n    setElasticNetParam(en_param)\n    pipeline_2 = Pipeline(stages=[va, pe,lr_2])\n    lr_pipeline_model_2 = pipeline_2.fit(training)\n    print('Accuracy with', level , 'degrees:', bce.evaluate(lr_pipeline_model_2.transform(validation)))"],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"markdown","source":["__After adding the regularization parameters, it did not have a major change in the accuracy.__"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\n# Index labels, adding metadata to the label column.\n# Fit on whole dataset to include all labels in index.\nli = StringIndexer(inputCol=\"default\", outputCol=\"indexedLabel\").fit(test_sdf)\n\n# Train a RandomForest model.\nrf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"features\")\n\n# Convert indexed labels back to original labels.\nlc = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=li.labels)\n\n# Chain indexers and forest in a Pipeline\nrf_pipeline = Pipeline(stages=[li, va, rf, lc])\n\n# Train model.  This also runs the indexers.\nrf_model = rf_pipeline.fit(training)\n\n# Compute accuracy\nevaluator = MulticlassClassificationEvaluator(\\\n                                              labelCol=\"indexedLabel\",\\\n                                              predictionCol=\"prediction\",\\\n                                              metricName=\"accuracy\")\n\nprint(evaluator.evaluate(rf_model.transform(validation)))"],"metadata":{},"outputs":[],"execution_count":52},{"cell_type":"markdown","source":["__After performing Random Forest, it has proved to be a better model than logistic regression with over 80% accuracy over validation.__"],"metadata":{}},{"cell_type":"markdown","source":["__Now we aim to implement a better random forest model by pruning the various number of trees.__"],"metadata":{}},{"cell_type":"code","source":["#Building a grid of number of trees using ParamGridBuilder\nfrom pyspark.ml.tuning import ParamGridBuilder\n\ngrid = ParamGridBuilder().\\\n    addGrid(rf.numTrees, range(5,20)).\\\n    build()"],"metadata":{"collapsed":true},"outputs":[],"execution_count":55},{"cell_type":"code","source":[" #Fitting the training data on \nall_models = []\ni = 5\n\nevaluator = MulticlassClassificationEvaluator(\n    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n\nfor j in range(len(grid)):\n    model = rf_pipeline.fit(training, grid[j])\n    accuracy = evaluator.evaluate(model.transform(validation))\n    print(\"Accuracy with \" + str(i) + \" trees: \" + str(accuracy))\n    i += 1"],"metadata":{},"outputs":[],"execution_count":56},{"cell_type":"markdown","source":["__Random Forest model with 7 trees gave us the maximum accuracy. Thus, we plan to use it as the best model.__"],"metadata":{}},{"cell_type":"code","source":["# Using Random Forest with 7 trees to find accuracy on the test dataset\nrf7 = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"features\", numTrees=7)\n\n#Chain indexers and forest in a Pipeline\nrf_pipeline = Pipeline(stages=[li, va, rf7, lc])\n\n#Train model.  This also runs the indexers.\nrf_model = rf_pipeline.fit(training)\n\n#Compute accuracy\nprint(evaluator.evaluate(rf_model.transform(testing)))"],"metadata":{},"outputs":[],"execution_count":58},{"cell_type":"markdown","source":["__The accuracy of Random Forest is 81.86%__"],"metadata":{}},{"cell_type":"code","source":["#Finding the importance of the features used\nimportances = rf_model.stages[2].featureImportances\nimportances"],"metadata":{},"outputs":[],"execution_count":60},{"cell_type":"markdown","source":["__It is evident from the sparse vector that some of the features are more important than the other in the model we have built. Hence, the banks can focus on those features more than the other features.__"],"metadata":{}},{"cell_type":"code","source":["predictions = lr_pipeline_model.transform(testing)\n\nfrom pyspark.mllib.evaluation import BinaryClassificationMetrics as metric\nfrom sklearn.metrics import roc_curve, auc, classification_report\n\nresults = predictions.select(['default', 'prediction'])\n \n## prepare score-label set\nresults_collect = results.collect()\nresults_list = [(float(i[0]), float(i[1])) for i in results_collect]\n \nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n \ny_test1 = [i[1] for i in results_list]\ny_score1 = [i[0] for i in results_list]\n \nfpr, tpr, threshold = roc_curve(y_test1, y_score1)\nroc_auc = auc(fpr, tpr)\n \n%matplotlib inline\nplt.figure()\nplt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()\n\ndisplay()"],"metadata":{},"outputs":[],"execution_count":62},{"cell_type":"markdown","source":["__We created the ROC curve by plotting True Positive Rate (TPR) against the False Positive Rate (FPR) at various thresholds. The Area under the curve (AUC) that we have plotted is on the higher side, which proves that the accuracy of our model is good.__"],"metadata":{}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n\nconf_mat = confusion_matrix(y_test1, y_score1)\nconf_mat\n\n## if mlxtend package is installed, the following code will generate a colored confusion matrix\n#from mlxtend.plotting import plot_confusion_matrix\n#fig, ax = plot_confusion_matrix(conf_mat=conf_mat, hide_ticks=True, cmap='flag')\n#plt.show()"],"metadata":{},"outputs":[],"execution_count":64},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n\nplt.matshow(conf_mat)\nplt.title('Confusion matrix')\nplt.colorbar()\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.show()\n\ndisplay()"],"metadata":{},"outputs":[],"execution_count":65},{"cell_type":"markdown","source":["__Here, the confusion matrix depicts the number of true positives and false negatives which is large. It means that the model is giving out good results.__"],"metadata":{}},{"cell_type":"code","source":["print (classification_report(y_test1, y_score1))"],"metadata":{},"outputs":[],"execution_count":67},{"cell_type":"markdown","source":["__The classification report shows that our model has given results with a high precision, that is desired by the bank to focus if a customer would be able to repay their loan or not. Moreover, this would assist them in giving loan to customers again, if they are able to repay their loan. Hence, the bank can use this model to forecast if the customer would be able to repay the loan amount in the given time span.__"],"metadata":{}},{"cell_type":"markdown","source":["### Appendix\n\n#### Version of different packages used in the project:\n\n__Python 2.7.6__\n\n__sklearn 0.17.1__\n\n__matplotlib 1.5.3__\n\n__numpy 1.11.1__\n\n__pandas 0.18.1 __\n\n__seaborn 0.7.1__"],"metadata":{"collapsed":true}}],"metadata":{"kernelspec":{"display_name":"Python [default]","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.5.3","nbconvert_exporter":"python","file_extension":".py"},"name":"DP_proj (1)","notebookId":3225796963562177},"nbformat":4,"nbformat_minor":0}
